{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fa3cea2",
   "metadata": {},
   "source": [
    "# multi-label stratification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8958fadd",
   "metadata": {},
   "source": [
    "## here we do train/dev splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc26e9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Original Data Info ---\n",
      "Total number of patients: 714\n",
      "\n",
      "Original Diagnosis Distribution:\n",
      "clinical_diagnosis\n",
      "AD     0.333333\n",
      "CN     0.333333\n",
      "FTD    0.333333\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Original Site Distribution:\n",
      "site\n",
      "Custodio      0.334734\n",
      "Lopera        0.214286\n",
      "Matallana     0.210084\n",
      "Avila         0.096639\n",
      "Slachevsky    0.085434\n",
      "Bruno         0.037815\n",
      "Behrens       0.021008\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "==================================================\n",
      "\n",
      "--- Combination Key Counts ---\n",
      "stratify_key\n",
      "FTD_Matallana     86\n",
      "CN_Custodio       80\n",
      "FTD_Custodio      80\n",
      "AD_Custodio       79\n",
      "AD_Lopera         76\n",
      "CN_Lopera         62\n",
      "CN_Matallana      39\n",
      "AD_Matallana      25\n",
      "AD_Slachevsky     24\n",
      "FTD_Avila         23\n",
      "AD_Avila          23\n",
      "FTD_Slachevsky    23\n",
      "CN_Avila          23\n",
      "FTD_Lopera        15\n",
      "CN_Slachevsky     14\n",
      "CN_Behrens        11\n",
      "AD_Bruno           9\n",
      "CN_Bruno           9\n",
      "FTD_Bruno          9\n",
      "AD_Behrens         2\n",
      "FTD_Behrens        2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==================================================\n",
      "\n",
      "--- Verification of Splits ---\n",
      "Total patients in sets: 714 (should match total)\n",
      "Training patients:   428\n",
      "Validation patients: 143\n",
      "Test patients:       143\n",
      "\n",
      "--- Diagnosis Distribution ---\n",
      "Train Set Diagnosis Distribution:\n",
      "clinical_diagnosis\n",
      "AD     0.331776\n",
      "CN     0.331776\n",
      "FTD    0.336449\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Validation Set Diagnosis Distribution:\n",
      "clinical_diagnosis\n",
      "AD     0.335664\n",
      "CN     0.342657\n",
      "FTD    0.321678\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Test Set Diagnosis Distribution:\n",
      "clinical_diagnosis\n",
      "AD     0.335664\n",
      "CN     0.328671\n",
      "FTD    0.335664\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "==================================================\n",
      "\n",
      "--- Site Distribution ---\n",
      "Train Set Site Distribution:\n",
      "site\n",
      "Avila         0.095794\n",
      "Behrens       0.025701\n",
      "Bruno         0.035047\n",
      "Custodio      0.334112\n",
      "Lopera        0.214953\n",
      "Matallana     0.210280\n",
      "Slachevsky    0.084112\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Validation Set Site Distribution:\n",
      "site\n",
      "Avila         0.097902\n",
      "Behrens       0.013986\n",
      "Bruno         0.041958\n",
      "Custodio      0.335664\n",
      "Lopera        0.216783\n",
      "Matallana     0.209790\n",
      "Slachevsky    0.083916\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Test Set Site Distribution:\n",
      "site\n",
      "Avila         0.097902\n",
      "Behrens       0.013986\n",
      "Bruno         0.041958\n",
      "Custodio      0.335664\n",
      "Lopera        0.209790\n",
      "Matallana     0.209790\n",
      "Slachevsky    0.090909\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --- 1. Load and Prepare Data ---\n",
    "\n",
    "metadata_df = pd.read_csv('../metadata/metadata.csv')\n",
    "\n",
    "print(\"--- Original Data Info ---\")\n",
    "print(f\"Total number of patients: {len(metadata_df)}\")\n",
    "print(\"\\nOriginal Diagnosis Distribution:\")\n",
    "print(metadata_df['clinical_diagnosis'].value_counts(normalize=True))\n",
    "print(\"\\nOriginal Site Distribution:\")\n",
    "print(metadata_df['site'].value_counts(normalize=True))\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "\n",
    "# --- 2. Create the Combination Key for Stratification ---\n",
    "metadata_df['stratify_key'] = metadata_df['clinical_diagnosis'] + '_' + metadata_df['site']\n",
    "\n",
    "print(\"--- Combination Key Counts ---\")\n",
    "print(metadata_df['stratify_key'].value_counts())\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "\n",
    "# --- 3. CRITICAL: Check for Rare Combinations ---\n",
    "# Stratification requires at least 2 samples for each class. If any combination\n",
    "# has only 1 sample, the split will fail.\n",
    "key_counts = metadata_df['stratify_key'].value_counts()\n",
    "if (key_counts < 2).any():\n",
    "    print(\"!!! WARNING: Found combinations with only 1 sample. !!!\")\n",
    "    print(\"The following combinations are too rare for stratification:\")\n",
    "    print(key_counts[key_counts < 2])\n",
    "    print(\"\\nYou must handle this before proceeding. Options:\")\n",
    "    print(\"1. Get more data for these groups.\")\n",
    "    print(\"2. Group rare sites together (e.g., 'SiteC' and 'SiteD' become 'Other_Site').\")\n",
    "    print(\"3. Remove these single-sample patients (last resort).\")\n",
    "    # Exit or handle the issue here. For this script, we'll assume no error.\n",
    "    # exit()\n",
    "\n",
    "\n",
    "# --- 4. Perform the Stratified Splits using the Combination Key ---\n",
    "\n",
    "# Define split proportions\n",
    "TEST_SIZE = 0.20      # 20% of patients for the test set\n",
    "VALIDATION_SIZE = 0.25 # 25% of the remaining 80% for validation (i.e., 20% of total)\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# First split: (Train + Validation) vs. Test\n",
    "# We split the DataFrame directly since each row is a patient\n",
    "train_val_df, test_df = train_test_split(\n",
    "    metadata_df,\n",
    "    test_size=TEST_SIZE,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=metadata_df['stratify_key'] # Stratify on our new key\n",
    ")\n",
    "\n",
    "# Second split: Train vs. Validation\n",
    "train_df, val_df = train_test_split(\n",
    "    train_val_df,\n",
    "    test_size=VALIDATION_SIZE,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=train_val_df['stratify_key'] # Stratify again on the same key\n",
    ")\n",
    "\n",
    "# Clean up the temporary key from the final dataframes\n",
    "train_df = train_df.drop(columns=['stratify_key'])\n",
    "val_df = val_df.drop(columns=['stratify_key'])\n",
    "test_df = test_df.drop(columns=['stratify_key'])\n",
    "\n",
    "\n",
    "# --- 5. Verification ---\n",
    "print(\"--- Verification of Splits ---\")\n",
    "print(f\"Total patients in sets: {len(train_df) + len(val_df) + len(test_df)} (should match total)\")\n",
    "print(f\"Training patients:   {len(train_df)}\")\n",
    "print(f\"Validation patients: {len(val_df)}\")\n",
    "print(f\"Test patients:       {len(test_df)}\\n\")\n",
    "\n",
    "print(\"--- Diagnosis Distribution ---\")\n",
    "print(\"Train Set Diagnosis Distribution:\")\n",
    "print(train_df['clinical_diagnosis'].value_counts(normalize=True).sort_index())\n",
    "print(\"\\nValidation Set Diagnosis Distribution:\")\n",
    "print(val_df['clinical_diagnosis'].value_counts(normalize=True).sort_index())\n",
    "print(\"\\nTest Set Diagnosis Distribution:\")\n",
    "print(test_df['clinical_diagnosis'].value_counts(normalize=True).sort_index())\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "\n",
    "print(\"--- Site Distribution ---\")\n",
    "print(\"Train Set Site Distribution:\")\n",
    "print(train_df['site'].value_counts(normalize=True).sort_index())\n",
    "print(\"\\nValidation Set Site Distribution:\")\n",
    "print(val_df['site'].value_counts(normalize=True).sort_index())\n",
    "print(\"\\nTest Set Site Distribution:\")\n",
    "print(test_df['site'].value_counts(normalize=True).sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53cd178",
   "metadata": {},
   "source": [
    "## Analysis of Your Results\n",
    "1. Successful Combination and Stratification:\n",
    "\n",
    "Combination Key Counts: You can see the breakdown of every diagnosis-site pair. Crucially, the smallest counts are AD_Behrens and FTD_Behrens with 2 samples each. Because no group had a count of 1, the train_test_split function was able to perform the stratification without errors. This is a perfect outcome.\n",
    "\n",
    "2. Perfect Split Proportions:\n",
    "\n",
    "#### Patient Counts:\n",
    "You started with 714 patients and ended with:\n",
    "Training: 428 patients (~60%)\n",
    "Validation: 143 patients (~20%)\n",
    "Test: 143 patients (~20%)\n",
    "Total: 428 + 143 + 143 = 714. The math is correct.\n",
    "\n",
    "3. Outstanding Distribution Balance (The Key Success Metric):\n",
    "\n",
    "#### Diagnosis Distribution: \n",
    "Look how closely the proportions match across the sets:\n",
    "\n",
    "Original: AD (33.3%), CN (33.3%), FTD (33.3%)\n",
    "Train: AD (33.1%), CN (33.1%), FTD (33.6%)\n",
    "Validation: AD (33.5%), CN (34.2%), FTD (32.1%)\n",
    "Test: AD (33.5%), CN (32.8%), FTD (33.5%)\n",
    "This is an almost perfect stratification. The very minor differences are due to the rounding required when dealing with a finite number of patients.\n",
    "Site Distribution: This is equally impressive. The proportions of patients from each site are very consistent across the three sets. For example:\n",
    "\n",
    "Custodio: ~33.4% in all three sets.\n",
    "Lopera: ~21.5% in all three sets.\n",
    "Even the smaller sites like Behrens and Bruno are represented proportionally (any small variations are expected due to the low absolute numbers).\n",
    "\n",
    "## Conclusion: \n",
    "You have successfully created high-quality, balanced, and non-overlapping training, validation, and test sets. You've accounted for the confounding variables of clinical_diagnosis and site, which gives your future models the best possible chance of learning true biological signals instead of dataset biases. This is a critical milestone passed with flying colors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83ec558",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf69b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrames saved successfully:\n",
      "- Training data: ../metadata/train_metadata.csv\n",
      "- Validation data: ../metadata/validation_metadata.csv\n",
      "- Test data: ../metadata/test_metadata.csv\n"
     ]
    }
   ],
   "source": [
    "# --- Define filenames ---\n",
    "train_output_path = '../metadata/train_metadata.csv'\n",
    "val_output_path = '../metadata/validation_metadata.csv'\n",
    "test_output_path = '../metadata/test_metadata.csv'\n",
    "\n",
    "# --- Save DataFrames to CSV ---\n",
    "# Using index=False is important to prevent pandas from writing the DataFrame index\n",
    "# as an extra column in your CSV files.\n",
    "train_df.to_csv(train_output_path, index=False)\n",
    "val_df.to_csv(val_output_path, index=False)\n",
    "test_df.to_csv(test_output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68ce636",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "redlat_classifier",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
